<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Zachery Moore" />

<meta name="date" content="2025-02-13" />

<title>1. Exporting data from the IncuCyte</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>







<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">1. Exporting data from the IncuCyte</h1>
<h4 class="author">Zachery Moore</h4>
<h4 class="date">2025-02-13</h4>



<div id="export" class="section level2">
<h2>Export</h2>
<p>There are multiple methods to export data from an IncuCyte.
<code>incur</code> expects data to be in the “Meta Imaging Series TIFF”
format. Here we are using IncuCyte 2022B Rev 2.</p>
<p>Open up the plate, and select “Export Images and Movies”. Then, make
sure to choose “As Stored”. For fluorescent data, if fluorophores have
overlapping spectra, ensure that the overlap percentages are correctly
set within “Spectral Unmixing”.</p>
<p>Make sure to choose “Uncalibrated” units for the export. Brief
testing shows that both “Calibrated” and “Uncalibrated” images produce
identical histograms when converted to 8-bit. This conversion is
required for the final merging of all channels. In addition, the sole
export option for “Calibrated” images are individual .tiff files which
lack metadata information.</p>
<p>Then, select scan times and wells as needed.</p>
<p>For the final step, make sure that the file format is set to “Meta
Imaging Series TIFF”. Don’t alter the file name prefix. Then, export
images to a folder of your choice. Make sure that all channels from each
plate are exported into separate folders. Your folder structure should
look like:</p>
<pre><code>plate/
  ├── phase
  ├── green
  └── red</code></pre>
<p>We then merge all channels together into a single .tiff file for each
well. To do this we use the <code>merge_incu_channels.py</code> script.
This script takes an arbitrary number of directories as arguments, with
each directory being added as a channel (in order), and the last
argument being the directory to save the merged image. For example,
using the above directory structure, running the following code in the
terminal:</p>
<pre><code>python merge_incu_channels.py phase/ green/ red/ composite/</code></pre>
<p>Will take the phase, green, and red images, merge into a new image
with channel 1 being phase, channel 2 being green etc., and then save
them in a new folder <code>composite/</code>. For each image (well),
this script will also produce a <code>datetime.csv</code> file which
contains the precise datetime for each image, and a
<code>metadata.csv</code> file that contains all IncuCyte-specific
metadata.</p>
</div>
<div id="tracking-segmentation" class="section level2">
<h2>Tracking &amp; Segmentation</h2>
<p>(can i provide a fiji binary or is that no bueno for
licensing???)</p>
<p>With merged images we can now perform tracking and segmentation
steps. We use and combination of <code>TrackMate</code>, a plugin for
FIJI/ImageJ, and <code>cellpose</code> for segmentation. First, ensure
that <code>TrackMate</code> is installed within your FIJI/ImageJ.
<code>TrackMate</code> can also work with other segmentation
algorithms/models, but we find both the provided and custom trained
models for <code>cellpose</code> to produce the best results.</p>
<p>Once a working environment is created, ensure that cellpose is able
to run. This is also a good opportunity to find an appropriate model for
your data, or even train a custom one on your own data. This is
recommended if you are going to be doing repeated analysis on similar
datasets.</p>
<p>With a working model, we can then move to <code>TrackMate</code> to
fine tune the tracking parameters. This is especially important if you
are looking to aggregate readouts across multiple cells within a well.
Once the tracking parameters have been fine tuned, we can then run the
process in one of two ways:</p>
<ol style="list-style-type: decimal">
<li>Using the TrackMate batcher in FIJI/ImageJ on our local
machine.</li>
<li>Running FIJI/ImageJ in headless mode on a HPC.</li>
</ol>
<p>Option 2 is the choice for large and/or repeated analyses. However,
this process HPC can be difficult. There are 2 provided scripts to aid
with this. First, the <code>trackmate_cellpose_segment.py</code>
contains a script that is provided to FIJI/ImageJ that contains all
<code>cellpose</code> and <code>TrackMate</code> parameters, and will
need to be modified to contain yours. This can be run like so:</p>
<pre><code># on linux
cd Fiji.app
./ImageJ-linux64 --headless path/to/script/trackmate_cellpose_segment.py</code></pre>
<p>On a SLURM-equipped HPC (like the one at WEHI), this process cannot
be achieved via the traditional <code>sbatch</code> command, as it needs
to be run in an interactive manner. The provided script
<code>example_slurm_srun.sh</code> that demonstrates how to achieve
this. The downside with this approach is that the machine it is run
needs to stay turned on/connected or else the interactive session stops.
As a workaround, we start a VM, then run the script from there. The
provided script also skips previously segmented images to save time as
well. This will then produce a <code>-spots.csv</code> containing
readouts across time and TrackMate <code>.xml</code> to view the data in
FIJI/ImageJ.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
