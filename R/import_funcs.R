#' Import TrackMate Spot Data from Python Processing Pipeline
#'
#' @description
#' Import and process TrackMate spot detection data that has been generated by
#' the companion Python scripts (`merge_incu_channels.py` and `trackmate_cellpose_segment.py`).
#' Automatically matches spot data with corresponding datetime information.
#'
#' @param path Character string specifying the directory containing both spot and datetime files.
#' @param spot_suffix Character string specifying the file suffix for spot data files
#'   (default: "-spots.csv").
#' @param time_suffix Character string specifying the file suffix for datetime files
#'   (default: "_datetime.csv").
#'
#' @return A named list where each element corresponds to a well, containing a data frame
#'   with spot tracking data including spatial coordinates, measurements, and timestamps.
#'
#' @details
#' This function expects files generated by the incur Python pipeline:
#' \itemize{
#'   \item Spot files: contain TrackMate tracking results with spatial and measurement data
#'   \item DateTime files: contain timestamp information for each frame
#'   \item File naming: should follow the pattern VID###_WELL#_#-spots.csv for spot files
#' }
#'
#' The function performs automatic data cleaning including:
#' \itemize{
#'   \item Column name standardization (lowercase, underscore separation)
#'   \item Type conversion for numeric columns
#'   \item Well identifier extraction from filenames
#'   \item Datetime integration with tracking data
#'   \item Frame index adjustment (converts from 0-based to 1-based indexing)
#' }
#'
#' @family data_import
#' @importFrom dplyr arrange bind_rows left_join mutate relocate rename slice
#' @importFrom purrr discard map map_chr map2
#' @importFrom readr read_csv
#' @importFrom rlang is_null sym is_na
#' @importFrom stringr str_extract str_remove str_replace_all str_split str_to_lower str_trim
#' @export
#'
#' @examples
#' \dontrun{
#' # Import TrackMate data from processed IncuCyte experiment
#' spot_data <- import_trackmate_spot_data(
#'   path = "/path/to/processed/incucyte/data",
#'   spot_suffix = "-spots.csv",
#'   time_suffix = "_datetime.csv"
#' )
#'
#' # Access data for specific well
#' well_A1_data <- spot_data[["A1"]]
#' }
import_trackmate_spot_data <- function(
  path,
  spot_suffix = "_merged_spots.csv",
  time_suffix = "_datetime.csv"
) {
  message(paste0("Processing:\n", path))
  spot_paths <- list.files(path, spot_suffix, full.names = TRUE)
  time_paths <- list.files(path, time_suffix, full.names = TRUE)

  if (length(spot_paths) != length(time_paths)) {
    message("Number of spot files does not equal number of time files")
    message("Is this an error in segmentation?")
  }

  # These should be ordered, but just to be safe:
  sort_order <- match(
    stringr::str_remove(basename(spot_paths), spot_suffix),
    stringr::str_remove(basename(time_paths), time_suffix)
  )
  spot_paths <- spot_paths[sort_order]
  time_paths <- time_paths[sort_order]

  # Fix NA
  spot_paths <- spot_paths[!is.na(spot_paths)]

  # Read in both sets of matched data
  spot_list <- purrr::map(spot_paths, function(x) {
    # An example of the file name:
    # VID207_B10_1_merged_spots.csv"
    well <- stringr::str_extract(x, "(?:VID\\d+_)([A-Z]\\d{1,2})(?:_)", 1)

    df <- readr::read_csv(x, show_col_types = FALSE)
    
    # Convert to integer/numeric where able
    df <- convert_character_columns(df)
    # Add in well column
    df <- dplyr::mutate(df, well = well) |> dplyr::relocate(well)

    # Edge case - there is a tibble but no spots
    if (nrow(df) == 0) {
      return(NA)
    } else {
      df
    }
  })

  # Remove NA
  spot_list <- purrr::discard(spot_list, rlang::is_na)

  # Names of list == wells
  names(spot_list) <- purrr::map_chr(spot_list, function(x) {
    unique(x$well)
  })

  # Read in the datetime data
  datetime_list <- purrr::map(time_paths, function(x) {
    readr::read_csv(
      x,
      show_col_types = FALSE,
      col_names = c("index", "datetime")
    ) |>
      dplyr::rename("frame" = index)
  })
  # Names of list == wells
  names(datetime_list) <- stringr::str_split(basename(time_paths), "_") |>
    purrr::map_chr(2)

  # Filter datetime for which spot data exists
  datetime_list <- datetime_list[names(datetime_list) %in% names(spot_list)]

  # Add in datetime to spot data
  spot_list <- purrr::map2(spot_list, datetime_list, function(x, y) {
    df <- dplyr::left_join(x, y, by = "frame")
    # Remove zero-based index
    df <- dplyr::mutate(df, !!rlang::sym("frame") := !!rlang::sym("frame") + 1)
    df <- dplyr::relocate(df, datetime)

    df
  })

  # Clean up column names
  spot_list <- purrr::map(spot_list, function(x) {
    colnames(x) <- colnames(x) |>
      stringr::str_to_lower() |>
      # Non alphanumeric to underscore
      stringr::str_replace_all("[^a-z0-9]+", "_") |>
      # Whitespace
      stringr::str_trim(side = "both") |>
      # Leading/trailing underscores
      stringr::str_replace_all("^_+|_+$", "") |>
      # Consecutive underscores
      stringr::str_replace_all("_+", "_")

    x
  })

  # Arrange
  spot_list <- purrr::map(spot_list, \(x) dplyr::arrange(x, datetime))

  spot_list
}

#' Summarize Multiple TrackMate Tracks per Time Point
#'
#' @description
#' When TrackMate detects multiple cellular objects per well at each time point,
#' summarize across tracks using specified aggregation functions. This is useful
#' for reducing multiple cell measurements to single values per time point.
#'
#' @param data_list A list of TrackMate data frames (typically from `import_trackmate_spot_data()`).
#' @param time_col Character string specifying the time column name (default: "datetime").
#' @param multi_spot_fun A named list of aggregation functions to apply across multiple
#'   spots per time point (default: `list(max = max)` for maximum values).
#'
#' @return A list of data frames with the same structure as input, but with multiple
#'   tracks per time point summarized according to the specified functions.
#'
#' @details
#' Common aggregation strategies include:
#' \itemize{
#'   \item Maximum values: `list(max = max)` - use largest measurement per time point
#'   \item Mean values: `list(mean = mean)` - average across all objects
#'   \item Median values: `list(median = median)` - robust central tendency
#'   \item Multiple metrics: `list(mean = mean, sd = sd)` - mean and standard deviation
#' }
#'
#' @family data_import
#' @importFrom dplyr across group_by summarise ungroup
#' @importFrom purrr map
#' @importFrom rlang ensym
#' @importFrom tidyselect everything
#' @export
#'
#' @examples
#' \dontrun{
#' # Use maximum values per time point (default)
#' summarized_data <- adjust_trackmate_multi_track(
#'   data_list = trackmate_data,
#'   time_col = "datetime"
#' )
#'
#' # Use mean values instead
#' mean_data <- adjust_trackmate_multi_track(
#'   data_list = trackmate_data,
#'   time_col = "datetime",
#'   multi_spot_fun = list(mean = mean)
#' )
#'
#' # Calculate multiple summary statistics
#' multi_summary <- adjust_trackmate_multi_track(
#'   data_list = trackmate_data,
#'   time_col = "datetime",
#'   multi_spot_fun = list(
#'     mean = mean,
#'     median = median,
#'     sd = sd
#'   )
#' )
#' }
adjust_trackmate_multi_track <- function(
  list,
  time_col = "datetime",
  multi_spot_fun = list(max = max)
) {
  purrr::map(list, function(x) {
    x <- dplyr::group_by(x, !!rlang::ensym(time_col))
    x <- dplyr::summarise(
      x,
      dplyr::across(
        .cols = tidyselect::everything(),
        .fns = multi_spot_fun,
        .names = "{.col}"
      )
    )
    x <- dplyr::ungroup(x)

    x
  })
}
